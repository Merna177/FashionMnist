{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson2_fashionMinST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Merna177/FashionMnist/blob/master/lesson2_fashionMinST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-X_3GhB6abo",
        "colab_type": "code",
        "outputId": "eea46e37-f142-4d3b-f064-1bb8fb2a6a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:02, 10542480.59it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 71863.39it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 3032987.52it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 24605.43it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Aq8peuF0qpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwZwSxBnMN7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1= nn.Linear(784,256)\n",
        "        self.fc2= nn.Linear(256,128)\n",
        "        self.fc3=nn.Linear(128,64)\n",
        "        self.fc4=nn.Linear(64,10)\n",
        "  def forward(self,x):\n",
        "     # make sure input tensor is flattened as x.shape[0] is batch size , -1 to flatten the remaining dimensions\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        return x\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMQi-ZBu4Xad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Network()\n",
        "#i used NLL because i used in last layer log softmax activation function\n",
        "criterion = nn.NLLLoss()\n",
        "#adam is a modified version of gredient descent but has momentum to speed up the process\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGjLQ5HW_VG9",
        "colab_type": "code",
        "outputId": "5077574a-2996-4fe5-d1e3-3f16efffb4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "epochs = 30\n",
        "steps = 0\n",
        "\n",
        "train_losses, test_losses = [], []\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_ps = model(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "            for images, labels in testloader:\n",
        "                log_ps = model(images)\n",
        "                test_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "                \n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        test_losses.append(test_loss/len(testloader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30..  Training Loss: 0.258..  Test Loss: 0.382..  Test Accuracy: 0.874\n",
            "Epoch: 2/30..  Training Loss: 0.255..  Test Loss: 0.359..  Test Accuracy: 0.876\n",
            "Epoch: 3/30..  Training Loss: 0.250..  Test Loss: 0.371..  Test Accuracy: 0.872\n",
            "Epoch: 4/30..  Training Loss: 0.242..  Test Loss: 0.361..  Test Accuracy: 0.879\n",
            "Epoch: 5/30..  Training Loss: 0.236..  Test Loss: 0.380..  Test Accuracy: 0.874\n",
            "Epoch: 6/30..  Training Loss: 0.233..  Test Loss: 0.362..  Test Accuracy: 0.883\n",
            "Epoch: 7/30..  Training Loss: 0.234..  Test Loss: 0.360..  Test Accuracy: 0.880\n",
            "Epoch: 8/30..  Training Loss: 0.219..  Test Loss: 0.377..  Test Accuracy: 0.882\n",
            "Epoch: 9/30..  Training Loss: 0.223..  Test Loss: 0.375..  Test Accuracy: 0.874\n",
            "Epoch: 10/30..  Training Loss: 0.211..  Test Loss: 0.385..  Test Accuracy: 0.881\n",
            "Epoch: 11/30..  Training Loss: 0.212..  Test Loss: 0.393..  Test Accuracy: 0.879\n",
            "Epoch: 12/30..  Training Loss: 0.206..  Test Loss: 0.389..  Test Accuracy: 0.883\n",
            "Epoch: 13/30..  Training Loss: 0.200..  Test Loss: 0.407..  Test Accuracy: 0.881\n",
            "Epoch: 14/30..  Training Loss: 0.203..  Test Loss: 0.394..  Test Accuracy: 0.881\n",
            "Epoch: 15/30..  Training Loss: 0.198..  Test Loss: 0.384..  Test Accuracy: 0.883\n",
            "Epoch: 16/30..  Training Loss: 0.189..  Test Loss: 0.432..  Test Accuracy: 0.882\n",
            "Epoch: 17/30..  Training Loss: 0.194..  Test Loss: 0.400..  Test Accuracy: 0.884\n",
            "Epoch: 18/30..  Training Loss: 0.188..  Test Loss: 0.436..  Test Accuracy: 0.881\n",
            "Epoch: 19/30..  Training Loss: 0.188..  Test Loss: 0.421..  Test Accuracy: 0.878\n",
            "Epoch: 20/30..  Training Loss: 0.191..  Test Loss: 0.431..  Test Accuracy: 0.880\n",
            "Epoch: 21/30..  Training Loss: 0.180..  Test Loss: 0.432..  Test Accuracy: 0.883\n",
            "Epoch: 22/30..  Training Loss: 0.179..  Test Loss: 0.440..  Test Accuracy: 0.886\n",
            "Epoch: 23/30..  Training Loss: 0.178..  Test Loss: 0.473..  Test Accuracy: 0.877\n",
            "Epoch: 24/30..  Training Loss: 0.172..  Test Loss: 0.468..  Test Accuracy: 0.877\n",
            "Epoch: 25/30..  Training Loss: 0.172..  Test Loss: 0.439..  Test Accuracy: 0.887\n",
            "Epoch: 26/30..  Training Loss: 0.182..  Test Loss: 0.463..  Test Accuracy: 0.876\n",
            "Epoch: 27/30..  Training Loss: 0.167..  Test Loss: 0.452..  Test Accuracy: 0.884\n",
            "Epoch: 28/30..  Training Loss: 0.165..  Test Loss: 0.474..  Test Accuracy: 0.871\n",
            "Epoch: 29/30..  Training Loss: 0.168..  Test Loss: 0.466..  Test Accuracy: 0.886\n",
            "Epoch: 30/30..  Training Loss: 0.162..  Test Loss: 0.478..  Test Accuracy: 0.886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn808ErYlQWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UUhZXkupKLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}